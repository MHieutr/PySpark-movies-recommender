{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation_system_pyspark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyspark \n",
        "# !pip install -U -q PyDrive\n",
        "# !apt install openjdk-8-jdk-headless -qq"
      ],
      "metadata": {
        "id": "BDOGhAD9X1zy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnEHi2mNyjzE"
      },
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmDJLb3iyn6t"
      },
      "source": [
        "import pandas as pd\n",
        "from pyspark.ml.feature import VectorAssembler, HashingTF, IDF, Normalizer, StopWordsRemover\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql.functions import col, isnan, when, trim\n",
        "\n",
        "import pyspark.sql.functions as psf\n",
        "from pyspark.sql.types import DoubleType"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6jvRY1Nys8F"
      },
      "source": [
        "movies = spark.read.csv('movies.csv',inferSchema=True, header =True)\n",
        "ratings = spark.read.csv('ratings.csv',inferSchema=True, header =True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0WSzHgGMCZr",
        "outputId": "b75615a6-3465-43ea-a703-d5c191ddf897"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|     1|      1|   4.0|964982703|\n",
            "|     1|      3|   4.0|964981247|\n",
            "|     1|      6|   4.0|964982224|\n",
            "|     1|     47|   5.0|964983815|\n",
            "|     1|     50|   5.0|964982931|\n",
            "|     1|     70|   3.0|964982400|\n",
            "|     1|    101|   5.0|964980868|\n",
            "|     1|    110|   4.0|964982176|\n",
            "|     1|    151|   5.0|964984041|\n",
            "|     1|    157|   5.0|964984100|\n",
            "|     1|    163|   5.0|964983650|\n",
            "|     1|    216|   5.0|964981208|\n",
            "|     1|    223|   3.0|964980985|\n",
            "|     1|    231|   5.0|964981179|\n",
            "|     1|    235|   4.0|964980908|\n",
            "|     1|    260|   5.0|964981680|\n",
            "|     1|    296|   3.0|964982967|\n",
            "|     1|    316|   3.0|964982310|\n",
            "|     1|    333|   5.0|964981179|\n",
            "|     1|    349|   4.0|964982563|\n",
            "+------+-------+------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqaAHE62MJ53",
        "outputId": "7378ad04-7ea5-4eba-dc56-58bf3ad7fa0e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            " |-- timestamp: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings = ratings.drop(\"timestamp\")\n",
        "# ratings.show()"
      ],
      "metadata": {
        "id": "PiXdXoOXMcS8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group data by userId, count ratings\n",
        "userId_ratings = ratings.groupBy(\"userId\").count().orderBy('count', ascending=False)\n",
        "userId_ratings.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWsxfAxNMsfQ",
        "outputId": "a59d73a8-84ab-4399-9bca-a89af18c405d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|userId|count|\n",
            "+------+-----+\n",
            "|   414| 2698|\n",
            "|   599| 2478|\n",
            "|   474| 2108|\n",
            "|   448| 1864|\n",
            "|   274| 1346|\n",
            "|   610| 1302|\n",
            "|    68| 1260|\n",
            "|   380| 1218|\n",
            "|   606| 1115|\n",
            "|   288| 1055|\n",
            "|   249| 1046|\n",
            "|   387| 1027|\n",
            "|   182|  977|\n",
            "|   307|  975|\n",
            "|   603|  943|\n",
            "|   298|  939|\n",
            "|   177|  904|\n",
            "|   318|  879|\n",
            "|   232|  862|\n",
            "|   480|  836|\n",
            "+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group data by userId, count ratings\n",
        "movieId_ratings = ratings.groupBy(\"movieId\").count().orderBy('count', ascending=False)\n",
        "movieId_ratings.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydRWy1rhMwhn",
        "outputId": "17edac22-41b3-4e4c-c7b5-b191e51c3a62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|movieId|count|\n",
            "+-------+-----+\n",
            "|    356|  329|\n",
            "|    318|  317|\n",
            "|    296|  307|\n",
            "|    593|  279|\n",
            "|   2571|  278|\n",
            "|    260|  251|\n",
            "|    480|  238|\n",
            "|    110|  237|\n",
            "|    589|  224|\n",
            "|    527|  220|\n",
            "|   2959|  218|\n",
            "|      1|  215|\n",
            "|   1196|  211|\n",
            "|     50|  204|\n",
            "|   2858|  204|\n",
            "|     47|  203|\n",
            "|    780|  202|\n",
            "|    150|  201|\n",
            "|   1198|  200|\n",
            "|   4993|  198|\n",
            "+-------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrDjwXsY9GgS"
      },
      "source": [
        "**Build up the content-based filtering algorithm with pairwise approach in TF-IDF vector space**\n",
        "\n",
        "The approach is based on the solution here:\n",
        "\n",
        "https://stackoverflow.com/questions/46758768/calculating-the-cosine-similarity-between-all-the-rows-of-a-dataframe-in-pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2GHdf-o9FUW"
      },
      "source": [
        "df = movies.select(\"movieId\", \"genres\").withColumn(\"genres\", psf.split( psf.lower(movies.genres), '\\|') )\n",
        "remover = StopWordsRemover(inputCol=\"genres\", outputCol=\"filtered\")\n",
        "df = remover.transform(df)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-twbV_CLM7ng",
        "outputId": "1c81f7bd-f1ba-4b66-cc07-17951455e8c2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+\n",
            "|movieId|              genres|            filtered|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|[adventure, anima...|[adventure, anima...|\n",
            "|      2|[adventure, child...|[adventure, child...|\n",
            "|      3|   [comedy, romance]|   [comedy, romance]|\n",
            "|      4|[comedy, drama, r...|[comedy, drama, r...|\n",
            "|      5|            [comedy]|            [comedy]|\n",
            "|      6|[action, crime, t...|[action, crime, t...|\n",
            "|      7|   [comedy, romance]|   [comedy, romance]|\n",
            "|      8|[adventure, child...|[adventure, child...|\n",
            "|      9|            [action]|            [action]|\n",
            "|     10|[action, adventur...|[action, adventur...|\n",
            "|     11|[comedy, drama, r...|[comedy, drama, r...|\n",
            "|     12|    [comedy, horror]|    [comedy, horror]|\n",
            "|     13|[adventure, anima...|[adventure, anima...|\n",
            "|     14|             [drama]|             [drama]|\n",
            "|     15|[action, adventur...|[action, adventur...|\n",
            "|     16|      [crime, drama]|      [crime, drama]|\n",
            "|     17|    [drama, romance]|    [drama, romance]|\n",
            "|     18|            [comedy]|            [comedy]|\n",
            "|     19|            [comedy]|            [comedy]|\n",
            "|     20|[action, comedy, ...|[action, comedy, ...|\n",
            "+-------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfGRqYq2XJSE"
      },
      "source": [
        "Compute TF-IDF:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucLgofFsJr-g"
      },
      "source": [
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"tf\")\n",
        "tf = hashingTF.transform(df)\n",
        "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\").fit(tf)\n",
        "tfidf = idf.transform(tf)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzfuWV0kOrW1",
        "outputId": "96e47ea2-ebd8-4e14-eb6c-17f138766f75"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|movieId|              genres|            filtered|                  tf|               tfidf|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      1|[adventure, anima...|[adventure, anima...|(262144,[30905,73...|(262144,[30905,73...|\n",
            "|      2|[adventure, child...|[adventure, child...|(262144,[30905,19...|(262144,[30905,19...|\n",
            "|      3|   [comedy, romance]|   [comedy, romance]|(262144,[73288,17...|(262144,[73288,17...|\n",
            "|      4|[comedy, drama, r...|[comedy, drama, r...|(262144,[6512,732...|(262144,[6512,732...|\n",
            "|      5|            [comedy]|            [comedy]|(262144,[73288],[...|(262144,[73288],[...|\n",
            "|      6|[action, crime, t...|[action, crime, t...|(262144,[33803,17...|(262144,[33803,17...|\n",
            "|      7|   [comedy, romance]|   [comedy, romance]|(262144,[73288,17...|(262144,[73288,17...|\n",
            "|      8|[adventure, child...|[adventure, child...|(262144,[30905,21...|(262144,[30905,21...|\n",
            "|      9|            [action]|            [action]|(262144,[257017],...|(262144,[257017],...|\n",
            "|     10|[action, adventur...|[action, adventur...|(262144,[171146,2...|(262144,[171146,2...|\n",
            "|     11|[comedy, drama, r...|[comedy, drama, r...|(262144,[6512,732...|(262144,[6512,732...|\n",
            "|     12|    [comedy, horror]|    [comedy, horror]|(262144,[73288,25...|(262144,[73288,25...|\n",
            "|     13|[adventure, anima...|[adventure, anima...|(262144,[30905,19...|(262144,[30905,19...|\n",
            "|     14|             [drama]|             [drama]|(262144,[6512],[1...|(262144,[6512],[0...|\n",
            "|     15|[action, adventur...|[action, adventur...|(262144,[175966,2...|(262144,[175966,2...|\n",
            "|     16|      [crime, drama]|      [crime, drama]|(262144,[6512,338...|(262144,[6512,338...|\n",
            "|     17|    [drama, romance]|    [drama, romance]|(262144,[6512,175...|(262144,[6512,175...|\n",
            "|     18|            [comedy]|            [comedy]|(262144,[73288],[...|(262144,[73288],[...|\n",
            "|     19|            [comedy]|            [comedy]|(262144,[73288],[...|(262144,[73288],[...|\n",
            "|     20|[action, comedy, ...|[action, comedy, ...|(262144,[6512,338...|(262144,[6512,338...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l5rsk6dXKBO"
      },
      "source": [
        "Compute L2 norm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufh8tT9XJ1_Z"
      },
      "source": [
        "normalizer = Normalizer(inputCol=\"tfidf\", outputCol=\"norm\")\n",
        "data = normalizer.transform(tfidf)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4gGZXoO-eX",
        "outputId": "81225dbe-9e94-4162-f883-04dd49060c02"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|movieId|              genres|            filtered|                  tf|               tfidf|                norm|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      1|[adventure, anima...|[adventure, anima...|(262144,[30905,73...|(262144,[30905,73...|(262144,[30905,73...|\n",
            "|      2|[adventure, child...|[adventure, child...|(262144,[30905,19...|(262144,[30905,19...|(262144,[30905,19...|\n",
            "|      3|   [comedy, romance]|   [comedy, romance]|(262144,[73288,17...|(262144,[73288,17...|(262144,[73288,17...|\n",
            "|      4|[comedy, drama, r...|[comedy, drama, r...|(262144,[6512,732...|(262144,[6512,732...|(262144,[6512,732...|\n",
            "|      5|            [comedy]|            [comedy]|(262144,[73288],[...|(262144,[73288],[...|(262144,[73288],[...|\n",
            "|      6|[action, crime, t...|[action, crime, t...|(262144,[33803,17...|(262144,[33803,17...|(262144,[33803,17...|\n",
            "|      7|   [comedy, romance]|   [comedy, romance]|(262144,[73288,17...|(262144,[73288,17...|(262144,[73288,17...|\n",
            "|      8|[adventure, child...|[adventure, child...|(262144,[30905,21...|(262144,[30905,21...|(262144,[30905,21...|\n",
            "|      9|            [action]|            [action]|(262144,[257017],...|(262144,[257017],...|(262144,[257017],...|\n",
            "|     10|[action, adventur...|[action, adventur...|(262144,[171146,2...|(262144,[171146,2...|(262144,[171146,2...|\n",
            "|     11|[comedy, drama, r...|[comedy, drama, r...|(262144,[6512,732...|(262144,[6512,732...|(262144,[6512,732...|\n",
            "|     12|    [comedy, horror]|    [comedy, horror]|(262144,[73288,25...|(262144,[73288,25...|(262144,[73288,25...|\n",
            "|     13|[adventure, anima...|[adventure, anima...|(262144,[30905,19...|(262144,[30905,19...|(262144,[30905,19...|\n",
            "|     14|             [drama]|             [drama]|(262144,[6512],[1...|(262144,[6512],[0...|(262144,[6512],[1...|\n",
            "|     15|[action, adventur...|[action, adventur...|(262144,[175966,2...|(262144,[175966,2...|(262144,[175966,2...|\n",
            "|     16|      [crime, drama]|      [crime, drama]|(262144,[6512,338...|(262144,[6512,338...|(262144,[6512,338...|\n",
            "|     17|    [drama, romance]|    [drama, romance]|(262144,[6512,175...|(262144,[6512,175...|(262144,[6512,175...|\n",
            "|     18|            [comedy]|            [comedy]|(262144,[73288],[...|(262144,[73288],[...|(262144,[73288],[...|\n",
            "|     19|            [comedy]|            [comedy]|(262144,[73288],[...|(262144,[73288],[...|(262144,[73288],[...|\n",
            "|     20|[action, comedy, ...|[action, comedy, ...|(262144,[6512,338...|(262144,[6512,338...|(262144,[6512,338...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rxeML_nXLpL"
      },
      "source": [
        "Compute matrix product (cos_similarity):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdPcMqITJ8iT"
      },
      "source": [
        "dot_udf = psf.udf(lambda x,y: float(x.dot(y)), DoubleType())\n",
        "\n",
        "cos_similarity = data.alias(\"i\").join(data.alias(\"j\"), psf.col(\"i.movieId\") < psf.col(\"j.movieId\"))\\\n",
        "                     .select(\n",
        "                         psf.col(\"i.movieId\").alias(\"i\"), \n",
        "                         psf.col(\"j.movieId\").alias(\"j\"), \n",
        "                         dot_udf(\"i.norm\", \"j.norm\").alias(\"dot\")).sort(\"i\", \"j\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxAW01RU0Z99"
      },
      "source": [
        "**Build up the Alternating Least Square (ALS) matrix factorization model in collaborative filtering algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZxzorlY-0X0"
      },
      "source": [
        "#Split training and testing data\n",
        "train_data,test_data = ratings.randomSplit([0.8,0.2])\n",
        "\n",
        "als = ALS(userCol='userId',itemCol='movieId',ratingCol='rating',coldStartStrategy=\"drop\")\n",
        "\n",
        "\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(als.regParam, [1, 0.1, 0.01]) \\\n",
        "    .addGrid(als.rank, [10, 20]) \\\n",
        "    .build()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUfr0t18_QVg"
      },
      "source": [
        "crossval = CrossValidator(estimator=als,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"rating\", metricName=\"mae\"),\n",
        "                          numFolds=3)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxFsL1qG_Q7b"
      },
      "source": [
        "cvModel = crossval.fit(train_data)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvBrF78fKSbB"
      },
      "source": [
        "best_rank = cvModel.bestModel._java_obj.parent().getRank()\n",
        "best_regParam = cvModel.bestModel._java_obj.parent().getRegParam()\n",
        "best_model_params = {'rank': best_rank, 'regParam': best_regParam}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9aAvIVM_UdU"
      },
      "source": [
        "pred = cvModel.transform(test_data)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL5e7nZBa5VU"
      },
      "source": [
        "def get_movieId( movie_name, movies_data ):\n",
        "    \"\"\"\n",
        "    return the movieId which is corresponding to the movie name\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    movie_name: string, the name of the movie w/ or w/o the year\n",
        "\n",
        "    movies_data: spark Dataframe, movies data with columns 'movieId','title'\n",
        "\n",
        "    Return\n",
        "    ------\n",
        "    the movieId\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    movieIds = []\n",
        "    for movie in movie_name:\n",
        "      Ids = movies_data.filter(movies_data.title.like('%{}%'.format(movie)) ).select('movieId').collect()\n",
        "      movieIds = list(set(movieIds + [ row.movieId for row in Ids ]  ))\n",
        "    return movieIds"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkaHOQ6H9Ink"
      },
      "source": [
        "**Make movie recommendation (item-based)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IwN-XalXaaB"
      },
      "source": [
        "def make_recommendation_item_based(similarity_matrix, ratings_data, movies_data,\n",
        "                        fav_movie, n_recommendations, userId=-99 ):\n",
        "    \"\"\"\n",
        "    Make top n movie recommendations. Currently, the movies the old user have watched are not excluded in the recommendation list yet.\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    similarity_matrix: spark Dataframe, the similarity matrix with columns 'i','j','dot'\n",
        "\n",
        "    ratings_data: spark Dataframe, ratings data with columns 'userId', 'movieId', 'rating' \n",
        "\n",
        "    movies_data: spark Dataframe, movies data with columns 'movieId','title'\n",
        "\n",
        "    fav_movie: str, name of user input movie\n",
        "\n",
        "    n_recommendations: int, top n recommendations\n",
        "\n",
        "    userId: int optional (default=-99), the user Id\n",
        "            if userId = -99, the new user will be created\n",
        "            if userId = -1, the latest inserted user is chosen\n",
        "\n",
        "    \"\"\"  \n",
        "  \n",
        "    movieIds = get_movieId(fav_movie, movies_data )\n",
        "\n",
        "    if (userId == -99):\n",
        "      userId = ratings_data.agg({\"userId\": \"max\"}).collect()[0][0] + 1\n",
        "    elif (userId == -1):\n",
        "      userId = ratings_data.agg({\"userId\": \"max\"}).collect()[0][0]\n",
        "\n",
        "  \n",
        "    df_similar_movieIds = similarity_matrix.filter( similarity_matrix.i.isin(movieIds) ).select('i','j','dot') \n",
        "  \n",
        "    df_similar_movieIds = df_similar_movieIds.filter( ~similarity_matrix.j.isin(movieIds) ).select('i','j','dot')\n",
        "\n",
        "    df_similar_movieIds = df_similar_movieIds.groupBy('j').agg( {'dot':'max'} ).select(col('j').alias('movieId'), col('max(dot)').alias('dot_max'))\n",
        " \n",
        "    topn_predictions = df_similar_movieIds.orderBy('dot_max', ascending=False).limit(10)\n",
        "\n",
        "    Ids = topn_predictions.select('movieId').collect()\n",
        "    Ids = [ row.movieId for row in Ids ]\n",
        "    topn_movies = movies_data.filter( movies_data.movieId.isin(Ids) ).select( 'title' )\n",
        "\n",
        "#    The following line is better, but it will produce error message...\n",
        "#    movieId#14 are ambiguous. It's probably because you joined several Datasets together, and some of these......\n",
        "#    topn_movies = movies_data.join( topn_predictions, topn_predictions.movieId == movies_data.movieId ).orderBy( 'dot_max', ascending=False ).select( 'title' )\n",
        "\n",
        "    return [row.title for row in topn_movies.collect()]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlUfZcys9DYe"
      },
      "source": [
        "**Make movie recommendation (user-based)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NprIVyJAXk91"
      },
      "source": [
        "def make_recommendation_user_based(best_model_params, ratings_data, movies_data,\n",
        "                        fav_movie, n_recommendations, userId=-99 ):\n",
        "    \"\"\"\n",
        "    make top n movie recommendations\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    best_model_params: dict, the best parameters of the model from the CrossValidator\n",
        "\n",
        "    ratings_data: spark Dataframe, ratings data with columns 'userId', 'movieId', 'rating' \n",
        "\n",
        "    movies_data: spark Dataframe, movies data with columns 'movieId','title'\n",
        "\n",
        "    fav_movie: str, name of user input movie\n",
        "\n",
        "    n_recommendations: int, top n recommendations\n",
        "\n",
        "    userId: int optional (default=-99), the user Id\n",
        "            if userId = -99, the new user will be created\n",
        "            if userId = -1, the latest inserted user is chosen\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    movieIds = get_movieId(fav_movie, movies_data )\n",
        "\n",
        "    if (userId == -99):\n",
        "      userId = ratings_data.agg({\"userId\": \"max\"}).collect()[0][0] + 1\n",
        "    elif (userId == -1):\n",
        "      userId = ratings_data.agg({\"userId\": \"max\"}).collect()[0][0]\n",
        "\n",
        "    max_rating = ratings_data.agg({\"rating\": \"max\"}).collect()[0][0]\n",
        "\n",
        "    # build up the train data, which is the original data + the new inserted data.\n",
        "    # We assume that the inserted favorate movie has the highest rating.\n",
        "    train_data = ratings_data\n",
        "    for movieId in movieIds:\n",
        "      new_rows = spark.createDataFrame([(userId,movieId,max_rating,0)], ['userId', 'movieId', 'rating', 'timestamp'])\n",
        "      train_data = ratings_data.union(new_rows)\n",
        "\n",
        "    # train best ALS\n",
        "    als = ALS(userCol='userId',itemCol='movieId',ratingCol='rating', \\\n",
        "              rank=best_model_params.get('rank'), \\\n",
        "              regParam=best_model_params.get('regParam'))\n",
        "\n",
        "    model = als.fit( train_data )\n",
        "    df_newuser = movies_data.filter(~movies_data.movieId.isin(movieIds)).select('movieId').withColumn(\"userId\", lit(userId))\n",
        "\n",
        "    predictions = model.transform(df_newuser)\n",
        "\n",
        "    def to_null(c):\n",
        "      return when(~(col(c).isNull() | isnan(col(c)) | (trim(col(c)) == \"\")), col(c))\n",
        "    \n",
        "    predictions = predictions.select([to_null(c).alias(c) for c in predictions.columns]).na.drop()\n",
        "\n",
        "    topn_predictions = predictions.orderBy('prediction', ascending=False).limit(n_recommendations)\n",
        "    topn_ids = topn_predictions.select('userId')\n",
        "    topn_movies = movies_data.join( topn_predictions, topn_predictions.movieId == movies_data.movieId ).orderBy( 'prediction', ascending=False ).select( 'title' )\n",
        "\n",
        "    return [row.title for row in topn_movies.collect()]\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_favorite_movies = [input(\"Movie: \")]"
      ],
      "metadata": {
        "id": "pkw1DMWvclxp",
        "outputId": "734056f1-8f7f-427e-b3f5-4f835acfeb7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie: aaaaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uuD3mK1LdIRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHE6EVb54Esq",
        "outputId": "d73a2d1c-9699-4f10-f2cc-91a6822c27b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#my_favorite_movies = ['Iron Man']\n",
        "# my_favorite_movies = ['Genius Party']\n",
        "# get recommends\n",
        "n_recommendations = 10\n",
        "recommends_item_based = make_recommendation_item_based(similarity_matrix = cos_similarity, ratings_data = ratings, movies_data = movies,\n",
        "                        fav_movie = my_favorite_movies, n_recommendations = n_recommendations )\n",
        "\n",
        "print(\"--------------Search based on similarity between movies--------------------------------------\")\n",
        "print('The users like' , my_favorite_movies , 'also like:')\n",
        "for i, title in enumerate(recommends_item_based):\n",
        "    print(i+1, title)\n",
        "if( len(recommends_item_based) < n_recommendations ):\n",
        "  print(\"Sadly, we couldn't offer so many recommendations :(\")\n",
        "\n",
        "recommends_user_based = make_recommendation_user_based(best_model_params = best_model_params, ratings_data = ratings, movies_data = movies,\n",
        "                        fav_movie = my_favorite_movies, n_recommendations = n_recommendations )\n",
        "\n",
        "print(\"--------------Search based on similarity between user's preference--------------------------------------\")\n",
        "print('The users like' , my_favorite_movies , 'also like:')\n",
        "for i, title in enumerate(recommends_user_based):\n",
        "    print(i+1, title)\n",
        "if( len(recommends_user_based) < n_recommendations ):\n",
        "  print(\"Sadly, we couldn't offer so many recommendations :(\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------Search based on similarity between movies--------------------------------------\n",
            "The users like ['aaaaa'] also like:\n",
            "Sadly, we couldn't offer so many recommendations :(\n",
            "--------------Search based on similarity between user's preference--------------------------------------\n",
            "The users like ['aaaaa'] also like:\n",
            "Sadly, we couldn't offer so many recommendations :(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7uRhT9Fxl49Q"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}